# í”„ë¡ íŠ¸ì—”ë“œ ìŒì„± ìƒíƒœ UI êµ¬í˜„ ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” ë°±ì—”ë“œì—ì„œ ì „ì†¡í•˜ëŠ” `speech_state` ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ì‚¬ìš©ìì—ê²Œ ì‹œê°ì  í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## 1. WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  êµ¬í˜„

### ê¸°ë³¸ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì¶”ê°€

í”„ë¡ íŠ¸ì—”ë“œì˜ WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì— `speech_state` ì²˜ë¦¬ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

```typescript
// WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì˜ˆì‹œ
websocket.onmessage = (event) => {
  const message = JSON.parse(event.data);

  switch (message.type) {
    case 'connected':
      handleConnected(message.sessionId);
      break;

    case 'input_transcription':
      handleInputTranscription(message.text, message.isFinal);
      break;

    case 'output_transcription':
      handleOutputTranscription(message.text, message.isFinal);
      break;

    case 'audio_response':
      handleAudioResponse(message.data, message.sampleRate);
      break;

    case 'turn_complete':
      handleTurnComplete(message.inputText, message.outputText);
      break;

    case 'speech_state':  // ìƒˆë¡œ ì¶”ê°€
      handleSpeechState(message.state, message.timestamp);
      break;

    case 'error':
      handleError(message.message, message.code);
      break;
  }
};
```

### ìŒì„± ìƒíƒœ í•¸ë“¤ëŸ¬ êµ¬í˜„

```typescript
// í˜„ì¬ ìŒì„± ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ë³€ìˆ˜
let currentSpeechState: 'speaking' | 'silent' | 'processing' = 'silent';

function handleSpeechState(state: string, timestamp: number) {
  console.log(`[${new Date(timestamp).toISOString()}] Speech state: ${state}`);

  currentSpeechState = state as 'speaking' | 'silent' | 'processing';

  // UI ì—…ë°ì´íŠ¸
  updateMicrophoneIndicator(state);
  updateStatusText(state);
}
```

## 2. UI ì»´í¬ë„ŒíŠ¸ êµ¬í˜„ ë°©ë²•

### ë°©ë²• 1: ë§ˆì´í¬ ì•„ì´ì½˜ ì• ë‹ˆë©”ì´ì…˜ (ì¶”ì²œ)

ê°€ì¥ ì§ê´€ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë§í•  ë•Œ ë§ˆì´í¬ ì•„ì´ì½˜ì´ ì‹œê°ì ìœ¼ë¡œ ë°˜ì‘í•©ë‹ˆë‹¤.

```typescript
function updateMicrophoneIndicator(state: string) {
  const micIcon = document.getElementById('microphone-icon');

  // ê¸°ì¡´ í´ë˜ìŠ¤ ì œê±°
  micIcon.classList.remove('speaking', 'silent', 'processing');

  // ìƒˆ ìƒíƒœ í´ë˜ìŠ¤ ì¶”ê°€
  micIcon.classList.add(state);
}
```

**CSS ìŠ¤íƒ€ì¼ ì˜ˆì‹œ**:
```css
#microphone-icon {
  width: 48px;
  height: 48px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: all 0.3s ease;
}

/* ëŒ€ê¸° ì¤‘ (ì¹¨ë¬µ) */
#microphone-icon.silent {
  background-color: #e0e0e0;
  border: 2px solid #9e9e9e;
}

/* ë§í•˜ëŠ” ì¤‘ */
#microphone-icon.speaking {
  background-color: #4caf50;
  border: 2px solid #2e7d32;
  animation: pulse 1.5s ease-in-out infinite;
  box-shadow: 0 0 20px rgba(76, 175, 80, 0.6);
}

/* ì²˜ë¦¬ ì¤‘ */
#microphone-icon.processing {
  background-color: #2196f3;
  border: 2px solid #1565c0;
  animation: spin 1s linear infinite;
}

/* í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ (ë§í•˜ëŠ” ì¤‘) */
@keyframes pulse {
  0%, 100% {
    transform: scale(1);
    box-shadow: 0 0 20px rgba(76, 175, 80, 0.6);
  }
  50% {
    transform: scale(1.1);
    box-shadow: 0 0 30px rgba(76, 175, 80, 0.8);
  }
}

/* íšŒì „ ì• ë‹ˆë©”ì´ì…˜ (ì²˜ë¦¬ ì¤‘) */
@keyframes spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}
```

### ë°©ë²• 2: íŒŒí˜• ì‹œê°í™” (ê³ ê¸‰)

ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ íŒŒí˜•ì„ í‘œì‹œí•˜ë©´ ë”ìš± ìƒë™ê° ìˆëŠ” UIê°€ ë©ë‹ˆë‹¤.

```typescript
// íŒŒí˜• ìº”ë²„ìŠ¤ ì„¤ì •
const waveformCanvas = document.getElementById('waveform') as HTMLCanvasElement;
const waveformCtx = waveformCanvas.getContext('2d');
let animationId: number | null = null;

function updateWaveform(state: string) {
  if (state === 'speaking') {
    startWaveformAnimation();
  } else {
    stopWaveformAnimation();
  }
}

function startWaveformAnimation() {
  if (animationId !== null) return;

  const bars = 20;
  const barWidth = waveformCanvas.width / bars;

  function animate() {
    waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);

    for (let i = 0; i < bars; i++) {
      const height = Math.random() * waveformCanvas.height * 0.8 + 10;
      const x = i * barWidth;
      const y = (waveformCanvas.height - height) / 2;

      waveformCtx.fillStyle = '#4caf50';
      waveformCtx.fillRect(x, y, barWidth - 2, height);
    }

    animationId = requestAnimationFrame(animate);
  }

  animate();
}

function stopWaveformAnimation() {
  if (animationId !== null) {
    cancelAnimationFrame(animationId);
    animationId = null;
    waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
  }
}

function handleSpeechState(state: string, timestamp: number) {
  currentSpeechState = state as any;
  updateMicrophoneIndicator(state);
  updateWaveform(state);  // íŒŒí˜• ì—…ë°ì´íŠ¸ ì¶”ê°€
  updateStatusText(state);
}
```

### ë°©ë²• 3: ìƒíƒœ í…ìŠ¤íŠ¸ í‘œì‹œ

ê°„ë‹¨í•˜ì§€ë§Œ ëª…í™•í•œ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

```typescript
function updateStatusText(state: string) {
  const statusElement = document.getElementById('speech-status');

  const statusMessages = {
    speaking: 'ğŸ¤ ë§ì”€í•˜ì„¸ìš”...',
    silent: 'ğŸ‘‚ ë“£ê³  ìˆìŠµë‹ˆë‹¤...',
    processing: 'â³ ì²˜ë¦¬ ì¤‘...'
  };

  statusElement.textContent = statusMessages[state] || '';
  statusElement.className = `status-${state}`;
}
```

**CSS ìŠ¤íƒ€ì¼**:
```css
#speech-status {
  font-size: 14px;
  font-weight: 500;
  padding: 8px 16px;
  border-radius: 20px;
  transition: all 0.3s ease;
}

.status-speaking {
  color: #2e7d32;
  background-color: #e8f5e9;
}

.status-silent {
  color: #616161;
  background-color: #f5f5f5;
}

.status-processing {
  color: #1565c0;
  background-color: #e3f2fd;
}
```

## 3. React ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ

Reactë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```tsx
import { useState, useEffect } from 'react';

interface SpeechStateIndicatorProps {
  websocket: WebSocket | null;
}

export function SpeechStateIndicator({ websocket }: SpeechStateIndicatorProps) {
  const [speechState, setSpeechState] = useState<'speaking' | 'silent' | 'processing'>('silent');

  useEffect(() => {
    if (!websocket) return;

    const handleMessage = (event: MessageEvent) => {
      const message = JSON.parse(event.data);

      if (message.type === 'speech_state') {
        setSpeechState(message.state);
      }
    };

    websocket.addEventListener('message', handleMessage);

    return () => {
      websocket.removeEventListener('message', handleMessage);
    };
  }, [websocket]);

  return (
    <div className="speech-state-indicator">
      <div className={`microphone-icon ${speechState}`}>
        <svg
          width="24"
          height="24"
          viewBox="0 0 24 24"
          fill="currentColor"
        >
          <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
          <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
        </svg>
      </div>

      <div className={`status-text status-${speechState}`}>
        {speechState === 'speaking' && 'ğŸ¤ ë§ì”€í•˜ì„¸ìš”...'}
        {speechState === 'silent' && 'ğŸ‘‚ ë“£ê³  ìˆìŠµë‹ˆë‹¤...'}
        {speechState === 'processing' && 'â³ ì²˜ë¦¬ ì¤‘...'}
      </div>
    </div>
  );
}
```

**React ì»´í¬ë„ŒíŠ¸ CSS**:
```css
.speech-state-indicator {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 12px;
}

.microphone-icon {
  width: 64px;
  height: 64px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: all 0.3s ease;
}

.microphone-icon.silent {
  background-color: #e0e0e0;
  color: #757575;
}

.microphone-icon.speaking {
  background-color: #4caf50;
  color: white;
  animation: pulse 1.5s ease-in-out infinite;
}

.microphone-icon.processing {
  background-color: #2196f3;
  color: white;
  animation: spin 1s linear infinite;
}

.status-text {
  font-size: 14px;
  font-weight: 500;
  padding: 6px 12px;
  border-radius: 16px;
}

.status-speaking {
  color: #2e7d32;
  background-color: #e8f5e9;
}

.status-silent {
  color: #616161;
  background-color: #f5f5f5;
}

.status-processing {
  color: #1565c0;
  background-color: #e3f2fd;
}
```

## 4. Vue.js ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ

```vue
<template>
  <div class="speech-state-indicator">
    <div :class="['microphone-icon', speechState]">
      <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
      </svg>
    </div>

    <div :class="['status-text', `status-${speechState}`]">
      {{ statusMessage }}
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, onUnmounted } from 'vue';

interface Props {
  websocket: WebSocket | null;
}

const props = defineProps<Props>();

const speechState = ref<'speaking' | 'silent' | 'processing'>('silent');

const statusMessage = computed(() => {
  switch (speechState.value) {
    case 'speaking':
      return 'ğŸ¤ ë§ì”€í•˜ì„¸ìš”...';
    case 'silent':
      return 'ğŸ‘‚ ë“£ê³  ìˆìŠµë‹ˆë‹¤...';
    case 'processing':
      return 'â³ ì²˜ë¦¬ ì¤‘...';
    default:
      return '';
  }
});

const handleMessage = (event: MessageEvent) => {
  const message = JSON.parse(event.data);

  if (message.type === 'speech_state') {
    speechState.value = message.state;
  }
};

onMounted(() => {
  if (props.websocket) {
    props.websocket.addEventListener('message', handleMessage);
  }
});

onUnmounted(() => {
  if (props.websocket) {
    props.websocket.removeEventListener('message', handleMessage);
  }
});
</script>

<style scoped>
/* ìœ„ì˜ CSS ìŠ¤íƒ€ì¼ê³¼ ë™ì¼ */
</style>
```

## 5. Claude CLIë¡œ êµ¬í˜„í•˜ê¸°

í”„ë¡ íŠ¸ì—”ë“œ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•œ í›„ Claude CLIë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

### ë‹¨ê³„ë³„ ëª…ë ¹ì–´

```bash
# 1. í”„ë¡ íŠ¸ì—”ë“œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /path/to/your/frontend/project

# 2. Claude CLI ì‹¤í–‰
claude

# 3. Claudeì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì²­
```

**Claude CLI í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ**:

```
ë°±ì—”ë“œì—ì„œ WebSocketìœ¼ë¡œ speech_state ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ìˆì–´.
ë©”ì‹œì§€ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„:

{
  "type": "speech_state",
  "state": "speaking" | "silent" | "processing",
  "timestamp": 1702345678901
}

í˜„ì¬ í”„ë¡œì íŠ¸ì— ë‹¤ìŒ ê¸°ëŠ¥ì„ êµ¬í˜„í•´ì¤˜:

1. WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì— speech_state ì¼€ì´ìŠ¤ ì¶”ê°€
2. ìŒì„± ìƒíƒœì— ë”°ë¼ ë§ˆì´í¬ ì•„ì´ì½˜ì´ ì‹œê°ì ìœ¼ë¡œ ë³€í•˜ëŠ” UI ì»´í¬ë„ŒíŠ¸ ìƒì„±
   - speaking: ì´ˆë¡ìƒ‰ ë°°ê²½, í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜
   - silent: íšŒìƒ‰ ë°°ê²½, ì •ì 
   - processing: íŒŒë€ìƒ‰ ë°°ê²½, íšŒì „ ì• ë‹ˆë©”ì´ì…˜
3. ìƒíƒœ í…ìŠ¤íŠ¸ í‘œì‹œ ("ë§ì”€í•˜ì„¸ìš”...", "ë“£ê³  ìˆìŠµë‹ˆë‹¤...", "ì²˜ë¦¬ ì¤‘...")

í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í”„ë ˆì„ì›Œí¬ëŠ” [React/Vue/Vanilla JS]ì´ê³ ,
WebSocket ì—°ê²°ì€ [íŒŒì¼ëª…ê³¼ ìœ„ì¹˜]ì—ì„œ ê´€ë¦¬í•˜ê³  ìˆì–´.
```

### React í”„ë¡œì íŠ¸ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸

```
React í”„ë¡œì íŠ¸ì— ìŒì„± ìƒíƒœ ì¸ë””ì¼€ì´í„°ë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ì–´.

ìš”êµ¬ì‚¬í•­:
1. src/components/SpeechStateIndicator.tsx íŒŒì¼ ìƒì„±
2. propsë¡œ websocket ê°ì²´ë¥¼ ë°›ìŒ
3. speech_state ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ìƒíƒœ ì—…ë°ì´íŠ¸
4. ë§ˆì´í¬ ì•„ì´ì½˜ê³¼ ìƒíƒœ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ëŠ” UI
5. CSS ì• ë‹ˆë©”ì´ì…˜ í¬í•¨ (í„ìŠ¤, íšŒì „)

ê¸°ì¡´ WebSocket ì—°ê²° ì½”ë“œ ìœ„ì¹˜: src/hooks/useWebSocket.ts
ë©”ì¸ ì»´í¬ë„ŒíŠ¸ ìœ„ì¹˜: src/App.tsx

ìœ„ ê°€ì´ë“œ ë¬¸ì„œ(FRONTEND_IMPLEMENTATION_GUIDE.md)ì˜ React ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ êµ¬í˜„í•´ì¤˜.
```

### Vue.js í”„ë¡œì íŠ¸ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸

```
Vue.js í”„ë¡œì íŠ¸ì— ìŒì„± ìƒíƒœ ì¸ë””ì¼€ì´í„°ë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ì–´.

ìš”êµ¬ì‚¬í•­:
1. src/components/SpeechStateIndicator.vue íŒŒì¼ ìƒì„±
2. Composition API ì‚¬ìš©
3. propsë¡œ websocket ê°ì²´ë¥¼ ë°›ìŒ
4. speech_state ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ìƒíƒœ ì—…ë°ì´íŠ¸
5. ë§ˆì´í¬ ì•„ì´ì½˜ê³¼ ìƒíƒœ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ëŠ” UI
6. CSS ì• ë‹ˆë©”ì´ì…˜ í¬í•¨ (í„ìŠ¤, íšŒì „)

ê¸°ì¡´ WebSocket ì—°ê²° ì½”ë“œ ìœ„ì¹˜: src/composables/useWebSocket.ts
ë©”ì¸ ì»´í¬ë„ŒíŠ¸ ìœ„ì¹˜: src/App.vue

ìœ„ ê°€ì´ë“œ ë¬¸ì„œ(FRONTEND_IMPLEMENTATION_GUIDE.md)ì˜ Vue ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ êµ¬í˜„í•´ì¤˜.
```

### Vanilla JS í”„ë¡œì íŠ¸ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸

```
Vanilla JavaScript í”„ë¡œì íŠ¸ì— ìŒì„± ìƒíƒœ ì¸ë””ì¼€ì´í„°ë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ì–´.

ìš”êµ¬ì‚¬í•­:
1. ê¸°ì¡´ WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì— speech_state ì¼€ì´ìŠ¤ ì¶”ê°€
2. updateMicrophoneIndicator() í•¨ìˆ˜ êµ¬í˜„
3. HTMLì— ë§ˆì´í¬ ì•„ì´ì½˜ê³¼ ìƒíƒœ í…ìŠ¤íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸ ì¶”ê°€
4. CSS ì• ë‹ˆë©”ì´ì…˜ ì •ì˜ (í„ìŠ¤, íšŒì „)

ê¸°ì¡´ WebSocket ì—°ê²° ì½”ë“œ ìœ„ì¹˜: js/websocket.js
ë©”ì¸ HTML íŒŒì¼: index.html

ìœ„ ê°€ì´ë“œ ë¬¸ì„œ(FRONTEND_IMPLEMENTATION_GUIDE.md)ì˜ Vanilla JS ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ êµ¬í˜„í•´ì¤˜.
```

## 6. í…ŒìŠ¤íŠ¸ ë°©ë²•

êµ¬í˜„ í›„ ë‹¤ìŒê³¼ ê°™ì´ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:

1. **WebSocket ì—°ê²° í™•ì¸**
   ```javascript
   console.log('WebSocket connected:', websocket.readyState === WebSocket.OPEN);
   ```

2. **ë©”ì‹œì§€ ìˆ˜ì‹  ë¡œê·¸**
   ```javascript
   websocket.onmessage = (event) => {
     const message = JSON.parse(event.data);
     console.log('Received:', message.type, message);
     // ê¸°ì¡´ í•¸ë“¤ëŸ¬...
   };
   ```

3. **ì‹¤ì œ ìŒì„± í…ŒìŠ¤íŠ¸**
   - ë§í•˜ê¸° ì‹œì‘ â†’ ë§ˆì´í¬ ì•„ì´ì½˜ì´ ì´ˆë¡ìƒ‰ìœ¼ë¡œ ë³€í•˜ê³  í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ
   - ë§ ë©ˆì¶¤ â†’ 300ms í›„ íšŒìƒ‰ìœ¼ë¡œ ë³€í•¨
   - ê³„ì† ë§í•˜ê¸° â†’ ì´ˆë¡ìƒ‰ ìœ ì§€

4. **ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬**
   ```
   Network â†’ WS â†’ Messages íƒ­ì—ì„œ speech_state ë©”ì‹œì§€ í™•ì¸
   ```

## 7. ë¬¸ì œ í•´ê²°

### ë©”ì‹œì§€ê°€ ìˆ˜ì‹ ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```javascript
// ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
websocket.onmessage = (event) => {
  const message = JSON.parse(event.data);
  console.log('[WS] Message type:', message.type);

  if (message.type === 'speech_state') {
    console.log('[WS] Speech state:', message.state, 'at', new Date(message.timestamp));
  }

  // ê¸°ì¡´ í•¸ë“¤ëŸ¬...
};
```

### ì• ë‹ˆë©”ì´ì…˜ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš°

1. CSS í´ë˜ìŠ¤ê°€ ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
   ```javascript
   console.log('Microphone classes:', micIcon.className);
   ```

2. ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ì¸ (CSS ì• ë‹ˆë©”ì´ì…˜ ì§€ì›)
   ```javascript
   console.log('Animation support:',
     CSS.supports('animation', 'pulse 1s ease-in-out infinite'));
   ```

### ìƒíƒœ ì „í™˜ì´ ë„ˆë¬´ ë¹ ë¥¸ ê²½ìš°

ë””ë°”ìš´ì‹± ì¶”ê°€:
```typescript
let stateChangeTimeout: NodeJS.Timeout | null = null;

function handleSpeechState(state: string, timestamp: number) {
  // ì´ì „ íƒ€ì´ë¨¸ ì·¨ì†Œ
  if (stateChangeTimeout) {
    clearTimeout(stateChangeTimeout);
  }

  // 50ms ë””ë°”ìš´ì‹±
  stateChangeTimeout = setTimeout(() => {
    currentSpeechState = state as any;
    updateMicrophoneIndicator(state);
    updateStatusText(state);
  }, 50);
}
```

## 8. ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´

### 1. ìŒì„± ë ˆë²¨ í‘œì‹œ
ë°±ì—”ë“œì—ì„œ ì—ë„ˆì§€ ë ˆë²¨ë„ ì „ì†¡í•˜ë„ë¡ ìˆ˜ì •í•˜ë©´ ì‹¤ì‹œê°„ ë³¼ë¥¨ ë¯¸í„° êµ¬í˜„ ê°€ëŠ¥

### 2. ì§„ë™ í”¼ë“œë°± (ëª¨ë°”ì¼)
```javascript
if (state === 'speaking' && navigator.vibrate) {
  navigator.vibrate(50);
}
```

### 3. ì†Œë¦¬ í”¼ë“œë°±
```javascript
const beep = new Audio('/sounds/beep.mp3');
if (state === 'speaking') {
  beep.play();
}
```

### 4. ì ‘ê·¼ì„± ê°œì„ 
```html
<div
  role="status"
  aria-live="polite"
  aria-label="ìŒì„± ìƒíƒœ"
>
  {statusMessage}
</div>
```

## ìš”ì•½

1. WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì— `speech_state` ì¼€ì´ìŠ¤ ì¶”ê°€
2. UI ì»´í¬ë„ŒíŠ¸ ìƒì„± (ë§ˆì´í¬ ì•„ì´ì½˜ + ìƒíƒœ í…ìŠ¤íŠ¸)
3. CSS ì• ë‹ˆë©”ì´ì…˜ ì •ì˜ (í„ìŠ¤, íšŒì „)
4. ìƒíƒœì— ë”°ë¼ UI ì—…ë°ì´íŠ¸
5. Claude CLIë¡œ í”„ë ˆì„ì›Œí¬ë³„ êµ¬í˜„ ìš”ì²­

ì´ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ Claude CLIì—ê²Œ êµ¬í˜„ì„ ìš”ì²­í•˜ë©´ ë©ë‹ˆë‹¤!
